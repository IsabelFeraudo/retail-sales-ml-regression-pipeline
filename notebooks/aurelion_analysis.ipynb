{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6ac97e",
   "metadata": {},
   "source": [
    "# Aurelion Sales Amount Prediction — End-to-End ML Pipeline\n",
    "\n",
    "**Author:** Isabel Feraudo  \n",
    "**Date:** 2025-11  \n",
    "\n",
    "## Summary\n",
    "This project implements an end-to-end Machine Learning pipeline to predict the total amount of a sales transaction line using structured retail data from Aurelion Store.\n",
    "The workflow covers data ingestion from multiple relational sources, preprocessing, feature engineering, model training, evaluation, and inference. Sales, products, and customer datasets are merged into a unified analytical dataset, where the target variable (importe) is derived from quantity and unit price.\n",
    "Two regression models are trained and compared — Linear Regression and Random Forest Regressor — using a reproducible preprocessing pipeline that includes numerical scaling and categorical encoding. Model performance is evaluated with MAE, RMSE, and R² metrics.\n",
    "The project follows a production-oriented structure with modular data loading, reusable pipelines, and environment reproducibility, demonstrating practical skills in machine learning engineering, data preparation, and model evaluation.\n",
    "\n",
    "###  Tech stack\n",
    "Python, Pandas, Scikit-learn, Matplotlib, Seaborn\n",
    "\n",
    "### Architecture\n",
    "Modular ML pipeline with reproducible project structure\n",
    "\n",
    "### Goal\n",
    "Demonstrate applied machine learning and pipeline design for real-world retail data.\n",
    "\n",
    "## Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff352ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1bf607",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4946732",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Quick preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88faa30f",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ae7d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "df.info()\n",
    "\n",
    "# Statistics\n",
    "df.describe()\n",
    "\n",
    "# Missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Example visualization\n",
    "plt.figure()\n",
    "df.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfaabcb",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13401b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example preprocessing steps\n",
    "\n",
    "# Drop missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Feature / target split\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c366dd",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c17f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedca1c0",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2820e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ee4311",
   "metadata": {},
   "source": [
    "### Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5327fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "save metrics\n",
    "results = {\n",
    "    \"model\": \"LinearRegression\",\n",
    "    \"mse\": mse\n",
    "}\n",
    "\n",
    "pd.DataFrame([results]).to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d939e11b",
   "metadata": {},
   "source": [
    "### Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e50cc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model, \"model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f374c85",
   "metadata": {},
   "source": [
    "# Conclusions (Markdown cell)\n",
    "## Results\n",
    "The Random Forest Regressor achieved the best predictive performance, outperforming the Linear Regression model across all evaluation metrics (MAE, RMSE, and R²). This indicates that the relationship between the predictors and the target variable is not purely linear and benefits from a non-linear modeling approach.\n",
    "The most influential factors in predicting the total transaction amount are quantity and unit price, which directly determine the monetary value of each sales line. The product category introduces additional variability that improves model accuracy when properly encoded.\n",
    "From a data perspective, the preprocessing pipeline successfully handled heterogeneous features by combining numerical scaling and categorical encoding in a reproducible workflow. The modular project structure enables consistent training, evaluation, and inference across environments.\n",
    "Overall, the results demonstrate that a structured machine learning pipeline can effectively model retail transaction behavior and provide reliable predictions for operational or analytical use cases.\n",
    "\n",
    "## Business Impact\n",
    "This predictive model can support data-driven decision making in retail operations by providing reliable estimates of transaction amounts before purchase completion.\n",
    "Potential applications include:\n",
    "\n",
    "**Revenue estimation and planning:**\n",
    "The model enables early prediction of sales value, helping forecast revenue trends and support financial planning.\n",
    "\n",
    "**Pricing and demand analysis:**\n",
    "By capturing the relationship between quantity, price, and category, the model can assist in identifying price-sensitive products and evaluating pricing strategies.\n",
    "\n",
    "**Operational optimization:**\n",
    "Predicted transaction values can inform inventory management, promotional strategies, and product prioritization.\n",
    "\n",
    "**Scalable analytics foundation:**\n",
    "The modular pipeline design allows easy integration into dashboards, APIs, or monitoring systems, making it suitable for production-oriented environments.\n",
    "\n",
    "This project demonstrates how machine learning pipelines can transform raw transactional data into actionable insights with direct business relevance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
